{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ad7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending path: /Users/afunnell/Code/equiboots/py_scripts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add path to import EquiBoots\n",
    "script_path = os.path.abspath(\"../py_scripts\")\n",
    "print(\"Appending path:\", script_path)\n",
    "sys.path.append(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f0e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equiboots as eqb\n",
    "\n",
    "from equiboots.tables import metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "febbe7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_biased_synthetic_data(n_samples=1000, bias_strength='moderate', random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with intentional bias to create statistically significant differences.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Number of samples to generate\n",
    "    - bias_strength: 'mild', 'moderate', or 'strong' - controls the level of bias\n",
    "    - random_seed: For reproducibility\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Define bias parameters based on strength\n",
    "    bias_params = {\n",
    "        'mild': {'race_bias': 0.15, 'sex_bias': 0.08, 'noise_level': 0.3},\n",
    "        'moderate': {'race_bias': 0.25, 'sex_bias': 0.15, 'noise_level': 0.2},\n",
    "        'strong': {'race_bias': 0.4, 'sex_bias': 0.25, 'noise_level': 0.1}\n",
    "    }\n",
    "    \n",
    "    params = bias_params[bias_strength]\n",
    "    \n",
    "    # Generate demographic variables\n",
    "    race = np.random.choice([\"white\", \"black\", \"asian\", \"hispanic\"], n_samples, \n",
    "                           p=[0.4, 0.3, 0.15, 0.15]).reshape(-1, 1)\n",
    "    sex = np.random.choice([\"M\", \"F\"], n_samples, p=[0.5, 0.5]).reshape(-1, 1)\n",
    "    \n",
    "    # Create bias mappings\n",
    "    race_bias_map = {\n",
    "        \"white\": 0.0,      # baseline\n",
    "        \"black\": -params['race_bias'],    # disadvantaged\n",
    "        \"asian\": params['race_bias'] * 0.5,  # slight advantage\n",
    "        \"hispanic\": -params['race_bias'] * 0.7  # disadvantaged\n",
    "    }\n",
    "    \n",
    "    sex_bias_map = {\n",
    "        \"M\": params['sex_bias'] * 0.5,   # slight advantage\n",
    "        \"F\": -params['sex_bias'] * 0.5   # slight disadvantage\n",
    "    }\n",
    "    \n",
    "    # Generate base probabilities with bias\n",
    "    base_prob = 0.5  # neutral starting point\n",
    "    \n",
    "    # Apply demographic biases\n",
    "    race_adjustments = np.array([race_bias_map[r[0]] for r in race])\n",
    "    sex_adjustments = np.array([sex_bias_map[s[0]] for s in sex])\n",
    "    \n",
    "    # Combine biases with some noise\n",
    "    noise = np.random.normal(0, params['noise_level'], n_samples)\n",
    "    \n",
    "    # Calculate biased probabilities\n",
    "    y_prob = base_prob + race_adjustments + sex_adjustments + noise\n",
    "    \n",
    "    # Clip to valid probability range\n",
    "    y_prob = np.clip(y_prob, 0.01, 0.99)\n",
    "    \n",
    "    # Generate predictions and true labels based on biased probabilities\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Make true labels correlated with the biased probabilities to simulate real bias\n",
    "    # Add some randomness to make it realistic\n",
    "    true_label_prob = y_prob * 0.8 + np.random.uniform(0, 0.4, n_samples)\n",
    "    true_label_prob = np.clip(true_label_prob, 0.01, 0.99)\n",
    "    y_true = np.random.binomial(1, true_label_prob)\n",
    "    \n",
    "    return y_true, y_prob, y_pred, race, sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e0f978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups created\n"
     ]
    }
   ],
   "source": [
    "y_true, y_prob, y_pred, race, sex = generate_biased_synthetic_data(\n",
    "    n_samples=1000, \n",
    "    bias_strength='moderate',  # Try 'mild', 'moderate', or 'strong'\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Create fairness DataFrame\n",
    "fairness_df = pd.DataFrame(\n",
    "    data=np.concatenate((race, sex), axis=1), \n",
    "    columns=[\"race\", \"sex\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize and process groups\n",
    "eq = eqb.EquiBoots(\n",
    "    y_true=y_true,\n",
    "    y_prob=y_prob,\n",
    "    y_pred=y_pred,\n",
    "    fairness_df=fairness_df,\n",
    "    fairness_vars=[\"race\", \"sex\"],\n",
    ")\n",
    "eq.grouper(groupings_vars=[\"race\", \"sex\"])\n",
    "sliced_race_data = eq.slicer(\"race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f7b975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_metrics = eq.get_metrics(sliced_race_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae4fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"test_type\": \"chi_square\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "}\n",
    "stat_test_results = eq.analyze_statistical_significance(\n",
    "    race_metrics, \"race\", test_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51a9e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_significant_table = metrics_table(race_metrics, stat_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "987b7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white *</th>\n",
       "      <th>hispanic * ▲</th>\n",
       "      <th>asian * ▲</th>\n",
       "      <th>black * ▲</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.655582</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.628866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.223140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697286</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP Rate</th>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.223140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP Rate</th>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.082353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN Rate</th>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN Rate</th>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>0.617577</td>\n",
       "      <td>0.496732</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.415808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Prevalence</th>\n",
       "      <td>0.520190</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.140893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.713187</td>\n",
       "      <td>0.673616</td>\n",
       "      <td>0.668475</td>\n",
       "      <td>0.726349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Precision Score</th>\n",
       "      <td>0.794003</td>\n",
       "      <td>0.677329</td>\n",
       "      <td>0.849831</td>\n",
       "      <td>0.624055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.625389</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.572701</td>\n",
       "      <td>0.680504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier Score</th>\n",
       "      <td>0.218167</td>\n",
       "      <td>0.265608</td>\n",
       "      <td>0.198621</td>\n",
       "      <td>0.233326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            white *  hispanic * ▲  asian * ▲   black * ▲\n",
       "Accuracy                   0.655582      0.588235   0.703704    0.628866\n",
       "Precision                  0.762557      0.760000   0.776699    0.658537\n",
       "Recall                     0.642308      0.250000   0.824742    0.223140\n",
       "F1 Score                   0.697286      0.376238   0.800000    0.333333\n",
       "Specificity                0.677019      0.922078   0.394737    0.917647\n",
       "TP Rate                    0.642308      0.250000   0.824742    0.223140\n",
       "FP Rate                    0.322981      0.077922   0.605263    0.082353\n",
       "FN Rate                    0.357692      0.750000   0.175258    0.776860\n",
       "TN Rate                    0.677019      0.922078   0.394737    0.917647\n",
       "TP                       167.000000     19.000000  80.000000   27.000000\n",
       "FP                        52.000000      6.000000  23.000000   14.000000\n",
       "FN                        93.000000     57.000000  17.000000   94.000000\n",
       "TN                       109.000000     71.000000  15.000000  156.000000\n",
       "Prevalence                 0.617577      0.496732   0.718519    0.415808\n",
       "Predicted Prevalence       0.520190      0.163399   0.762963    0.140893\n",
       "ROC AUC                    0.713187      0.673616   0.668475    0.726349\n",
       "Average Precision Score    0.794003      0.677329   0.849831    0.624055\n",
       "Log Loss                   0.625389      0.823800   0.572701    0.680504\n",
       "Brier Score                0.218167      0.265608   0.198621    0.233326"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_significant_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f9a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_test_results['omnibus'].is_significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dadc1e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds [0, 11, 22, 33, 44, 55, 66, 77, 88, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping iterations: 100%|██████████| 1000/1000 [00:01<00:00, 919.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups created\n"
     ]
    }
   ],
   "source": [
    "int_list = np.linspace(0, 100, num=10, dtype=int).tolist()\n",
    "eq2 = eqb.EquiBoots(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    fairness_df,\n",
    "    [\"race\", \"sex\"],\n",
    "    y_prob,\n",
    "    seeds=int_list,\n",
    "    reference_groups=[\"white\", \"M\"],\n",
    "    task=\"binary_classification\",\n",
    "    bootstrap_flag=True,\n",
    "    num_bootstraps=1000,\n",
    "    boot_sample_size=1000,\n",
    "    balanced=True,  # False is stratified, True is balanced\n",
    "    # stratify_by_outcome=True,\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "eq2.set_fix_seeds(int_list)\n",
    "print(\"seeds\", eq2.seeds)\n",
    "\n",
    "eq2.grouper(groupings_vars=[\"race\", \"sex\"])\n",
    "\n",
    "boots_race_data = eq2.slicer(\"race\")\n",
    "race_metrics = eq2.get_metrics(boots_race_data)\n",
    "dispa = eq2.calculate_disparities(race_metrics, \"race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fcecf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = eq2.calculate_differences(race_metrics, \"race\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "396eff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_boot = ['Accuracy_diff', \"Precision_diff\"]\n",
    "\n",
    "\n",
    "test_config = {\n",
    "    \"test_type\": \"bootstrap_test\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "    \"tail_type\": \"two_tailed\",\n",
    "    \"metrics\": metrics_boot,\n",
    "}\n",
    "\n",
    "stat_test_results = eq.analyze_statistical_significance(\n",
    "    race_metrics, \"race\", test_config, diffs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed02c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hispanic': {'Accuracy_diff': StatTestResult(statistic=-0.06160000000000002, p_value=0.0, is_significant=True, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.15337655620367746, 0.03017655620367741)),\n",
       "  'Precision_diff': StatTestResult(statistic=0.006086344823399714, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.1328678614258402, 0.1450405510726396))},\n",
       " 'asian': {'Accuracy_diff': StatTestResult(statistic=0.030399999999999986, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.05913925517414949, 0.11993925517414945)),\n",
       "  'Precision_diff': StatTestResult(statistic=0.018488777078749054, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.08312843130270478, 0.1201059854602029))},\n",
       " 'black': {'Accuracy_diff': StatTestResult(statistic=-0.018800000000000004, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.10177294040887777, 0.06417294040887778)),\n",
       "  'Precision_diff': StatTestResult(statistic=-0.12259888613669702, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.38432262467313105, 0.13912485239973704))}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91d3c860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_diff</th>\n",
       "      <td>-0.061600 *</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision_diff</th>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.018489</td>\n",
       "      <td>-0.122599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall_diff</th>\n",
       "      <td>-0.397821</td>\n",
       "      <td>0.172338</td>\n",
       "      <td>-0.428352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Score_diff</th>\n",
       "      <td>-0.321455</td>\n",
       "      <td>0.098375</td>\n",
       "      <td>-0.371676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity_diff</th>\n",
       "      <td>0.241809</td>\n",
       "      <td>-0.303089</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_Rate_diff</th>\n",
       "      <td>-0.397821</td>\n",
       "      <td>0.172338</td>\n",
       "      <td>-0.428352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP_Rate_diff</th>\n",
       "      <td>-0.241809</td>\n",
       "      <td>0.303089</td>\n",
       "      <td>-0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN_Rate_diff</th>\n",
       "      <td>0.397821</td>\n",
       "      <td>-0.172338</td>\n",
       "      <td>0.428352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN_Rate_diff</th>\n",
       "      <td>0.241809</td>\n",
       "      <td>-0.303089</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence_diff</th>\n",
       "      <td>-0.1112</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>-0.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_Prevalence_diff</th>\n",
       "      <td>-0.3536</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>-0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC_AUC_diff</th>\n",
       "      <td>-0.060209</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>0.015968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average_Precision_Score_diff</th>\n",
       "      <td>-0.126165</td>\n",
       "      <td>0.064517</td>\n",
       "      <td>-0.174832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log_Loss_diff</th>\n",
       "      <td>0.196754</td>\n",
       "      <td>-0.049071</td>\n",
       "      <td>0.023626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier_Score_diff</th>\n",
       "      <td>0.045801</td>\n",
       "      <td>-0.017095</td>\n",
       "      <td>0.005597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hispanic     asian     black\n",
       "Accuracy_diff                 -0.061600 *  0.030400 -0.018800\n",
       "Precision_diff                   0.006086  0.018489 -0.122599\n",
       "Recall_diff                     -0.397821  0.172338 -0.428352\n",
       "F1_Score_diff                   -0.321455  0.098375 -0.371676\n",
       "Specificity_diff                 0.241809 -0.303089  0.235490\n",
       "TP_Rate_diff                    -0.397821  0.172338 -0.428352\n",
       "FP_Rate_diff                    -0.241809  0.303089 -0.235490\n",
       "FN_Rate_diff                     0.397821 -0.172338  0.428352\n",
       "TN_Rate_diff                     0.241809 -0.303089  0.235490\n",
       "Prevalence_diff                   -0.1112  0.120400 -0.198800\n",
       "Predicted_Prevalence_diff         -0.3536  0.249200 -0.376000\n",
       "ROC_AUC_diff                    -0.060209 -0.054813  0.015968\n",
       "Average_Precision_Score_diff    -0.126165  0.064517 -0.174832\n",
       "Log_Loss_diff                    0.196754 -0.049071  0.023626\n",
       "Brier_Score_diff                 0.045801 -0.017095  0.005597"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table(race_metrics, statistical_tests=stat_test_results, differences=diffs, reference_group=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882ac69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equiboots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
