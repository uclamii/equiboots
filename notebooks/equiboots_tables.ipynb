{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending path: /home/afunnell/Code/EquiBoots/equi_boots/py_scripts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add path to import EquiBoots\n",
    "script_path = os.path.abspath(\"../py_scripts\")\n",
    "print(\"Appending path:\", script_path)\n",
    "sys.path.append(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equiboots as eqb\n",
    "\n",
    "from equiboots.tables import metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_biased_synthetic_data(n_samples=1000, bias_strength='moderate', random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with intentional bias to create statistically significant differences.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Number of samples to generate\n",
    "    - bias_strength: 'mild', 'moderate', or 'strong' - controls the level of bias\n",
    "    - random_seed: For reproducibility\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Define bias parameters based on strength\n",
    "    bias_params = {\n",
    "        'mild': {'race_bias': 0.15, 'sex_bias': 0.08, 'noise_level': 0.3},\n",
    "        'moderate': {'race_bias': 0.25, 'sex_bias': 0.15, 'noise_level': 0.2},\n",
    "        'strong': {'race_bias': 0.4, 'sex_bias': 0.25, 'noise_level': 0.1}\n",
    "    }\n",
    "    \n",
    "    params = bias_params[bias_strength]\n",
    "    \n",
    "    # Generate demographic variables\n",
    "    race = np.random.choice([\"white\", \"black\", \"asian\", \"hispanic\"], n_samples, \n",
    "                           p=[0.4, 0.3, 0.15, 0.15]).reshape(-1, 1)\n",
    "    sex = np.random.choice([\"M\", \"F\"], n_samples, p=[0.5, 0.5]).reshape(-1, 1)\n",
    "    \n",
    "    # Create bias mappings\n",
    "    race_bias_map = {\n",
    "        \"white\": 0.0,      # baseline\n",
    "        \"black\": -params['race_bias'],    # disadvantaged\n",
    "        \"asian\": params['race_bias'] * 0.5,  # slight advantage\n",
    "        \"hispanic\": -params['race_bias'] * 0.7  # disadvantaged\n",
    "    }\n",
    "    \n",
    "    sex_bias_map = {\n",
    "        \"M\": params['sex_bias'] * 0.5,   # slight advantage\n",
    "        \"F\": -params['sex_bias'] * 0.5   # slight disadvantage\n",
    "    }\n",
    "    \n",
    "    # Generate base probabilities with bias\n",
    "    base_prob = 0.5  # neutral starting point\n",
    "    \n",
    "    # Apply demographic biases\n",
    "    race_adjustments = np.array([race_bias_map[r[0]] for r in race])\n",
    "    sex_adjustments = np.array([sex_bias_map[s[0]] for s in sex])\n",
    "    \n",
    "    # Combine biases with some noise\n",
    "    noise = np.random.normal(0, params['noise_level'], n_samples)\n",
    "    \n",
    "    # Calculate biased probabilities\n",
    "    y_prob = base_prob + race_adjustments + sex_adjustments + noise\n",
    "    \n",
    "    # Clip to valid probability range\n",
    "    y_prob = np.clip(y_prob, 0.01, 0.99)\n",
    "    \n",
    "    # Generate predictions and true labels based on biased probabilities\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Make true labels correlated with the biased probabilities to simulate real bias\n",
    "    # Add some randomness to make it realistic\n",
    "    true_label_prob = y_prob * 0.8 + np.random.uniform(0, 0.4, n_samples)\n",
    "    true_label_prob = np.clip(true_label_prob, 0.01, 0.99)\n",
    "    y_true = np.random.binomial(1, true_label_prob)\n",
    "    \n",
    "    return y_true, y_prob, y_pred, race, sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups created\n"
     ]
    }
   ],
   "source": [
    "y_true, y_prob, y_pred, race, sex = generate_biased_synthetic_data(\n",
    "    n_samples=1000, \n",
    "    bias_strength='moderate',\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Create fairness DataFrame\n",
    "fairness_df = pd.DataFrame(\n",
    "    data=np.concatenate((race, sex), axis=1), \n",
    "    columns=[\"race\", \"sex\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize and process groups\n",
    "eq = eqb.EquiBoots(\n",
    "    y_true=y_true,\n",
    "    y_prob=y_prob,\n",
    "    y_pred=y_pred,\n",
    "    fairness_df=fairness_df,\n",
    "    fairness_vars=[\"race\", \"sex\"],\n",
    ")\n",
    "eq.grouper(groupings_vars=[\"race\", \"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_race_data = eq.slicer(\"race\")\n",
    "race_metrics = eq.get_metrics(sliced_race_data)\n",
    "\n",
    "sliced_sex_data = eq.slicer(\"sex\")\n",
    "sex_metrics = eq.get_metrics(sliced_sex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"test_type\": \"chi_square\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "}\n",
    "stat_test_results_race = eq.analyze_statistical_significance(\n",
    "    race_metrics, \"race\", test_config\n",
    ")\n",
    "\n",
    "stat_test_results_sex = eq.analyze_statistical_significance(\n",
    "    sex_metrics, \"sex\", test_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white *</th>\n",
       "      <th>hispanic * ▲</th>\n",
       "      <th>asian * ▲</th>\n",
       "      <th>black * ▲</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.655582</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.628866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.223140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697286</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP Rate</th>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.223140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP Rate</th>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.082353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN Rate</th>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN Rate</th>\n",
       "      <td>0.677019</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>0.617577</td>\n",
       "      <td>0.496732</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.415808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Prevalence</th>\n",
       "      <td>0.520190</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.140893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.713187</td>\n",
       "      <td>0.673616</td>\n",
       "      <td>0.668475</td>\n",
       "      <td>0.726349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Precision Score</th>\n",
       "      <td>0.794003</td>\n",
       "      <td>0.677329</td>\n",
       "      <td>0.849831</td>\n",
       "      <td>0.624055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.625389</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.572701</td>\n",
       "      <td>0.680504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier Score</th>\n",
       "      <td>0.218167</td>\n",
       "      <td>0.265608</td>\n",
       "      <td>0.198621</td>\n",
       "      <td>0.233326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            white *  hispanic * ▲  asian * ▲   black * ▲\n",
       "Accuracy                   0.655582      0.588235   0.703704    0.628866\n",
       "Precision                  0.762557      0.760000   0.776699    0.658537\n",
       "Recall                     0.642308      0.250000   0.824742    0.223140\n",
       "F1 Score                   0.697286      0.376238   0.800000    0.333333\n",
       "Specificity                0.677019      0.922078   0.394737    0.917647\n",
       "TP Rate                    0.642308      0.250000   0.824742    0.223140\n",
       "FP Rate                    0.322981      0.077922   0.605263    0.082353\n",
       "FN Rate                    0.357692      0.750000   0.175258    0.776860\n",
       "TN Rate                    0.677019      0.922078   0.394737    0.917647\n",
       "TP                       167.000000     19.000000  80.000000   27.000000\n",
       "FP                        52.000000      6.000000  23.000000   14.000000\n",
       "FN                        93.000000     57.000000  17.000000   94.000000\n",
       "TN                       109.000000     71.000000  15.000000  156.000000\n",
       "Prevalence                 0.617577      0.496732   0.718519    0.415808\n",
       "Predicted Prevalence       0.520190      0.163399   0.762963    0.140893\n",
       "ROC AUC                    0.713187      0.673616   0.668475    0.726349\n",
       "Average Precision Score    0.794003      0.677329   0.849831    0.624055\n",
       "Log Loss                   0.625389      0.823800   0.572701    0.680504\n",
       "Brier Score                0.218167      0.265608   0.198621    0.233326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_test_results_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_stat_results = {\"sex\": stat_test_results_sex, \"race\": stat_test_results_race}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds [0, 11, 22, 33, 44, 55, 66, 77, 88, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping iterations: 100%|██████████| 1000/1000 [00:02<00:00, 438.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups created\n"
     ]
    }
   ],
   "source": [
    "# Run with custom y_lim and adjusted thresholds\n",
    "eqb.eq_group_metrics_point_plot(\n",
    "    group_metrics=[race_metrics, sex_metrics],\n",
    "    metric_cols=[\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "    ],\n",
    "    category_names=[\"race\"],\n",
    "    figsize=(6, 8),\n",
    "    include_legend=True,\n",
    "    plot_thresholds=(0.9, 1.1),\n",
    "    raw_metrics=True,\n",
    "    show_grid=True,\n",
    "    y_lim=(0, 1),\n",
    "    statistical_tests=overall_stat_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_significant_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results['omnibus'].is_significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list = np.linspace(0, 100, num=10, dtype=int).tolist()\n",
    "eq2 = eqb.EquiBoots(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    fairness_df,\n",
    "    [\"race\", \"sex\"],\n",
    "    y_prob,\n",
    "    seeds=int_list,\n",
    "    reference_groups=[\"white\", \"M\"],\n",
    "    task=\"binary_classification\",\n",
    "    bootstrap_flag=True,\n",
    "    num_bootstraps=1000,\n",
    "    boot_sample_size=1000,\n",
    "    balanced=True,  # False is stratified, True is balanced\n",
    "    # stratify_by_outcome=True,\n",
    ")\n",
    "\n",
    "# Set seeds\n",
    "eq2.set_fix_seeds(int_list)\n",
    "print(\"seeds\", eq2.seeds)\n",
    "\n",
    "eq2.grouper(groupings_vars=[\"race\", \"sex\"])\n",
    "\n",
    "boots_race_data = eq2.slicer(\"race\")\n",
    "race_metrics = eq2.get_metrics(boots_race_data)\n",
    "dispa = eq2.calculate_disparities(race_metrics, \"race\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "13",
=======
   "execution_count": 11,
   "id": "10",
>>>>>>> 6d5d91d719cd19268f8a746cc04da2e4ea9866ac
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = eq2.calculate_differences(race_metrics, \"race\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "14",
=======
   "execution_count": 12,
   "id": "11",
>>>>>>> 6d5d91d719cd19268f8a746cc04da2e4ea9866ac
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_boot = ['Accuracy_diff', \"Precision_diff\", \"Recall_diff\"]\n",
    "\n",
    "\n",
    "test_config = {\n",
    "    \"test_type\": \"bootstrap_test\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "    \"tail_type\": \"two_tailed\",\n",
    "    \"metrics\": metrics_boot,\n",
    "}\n",
    "\n",
    "stat_test_results = eq.analyze_statistical_significance(\n",
    "    race_metrics, \"race\", test_config, diffs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table(race_metrics, statistical_tests=stat_test_results, differences=diffs, reference_group=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 13,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hispanic': {'Accuracy_diff': StatTestResult(statistic=-0.06160000000000002, p_value=0.0, is_significant=True, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.15337655620367746, 0.03017655620367741)),\n",
       "  'Precision_diff': StatTestResult(statistic=0.006086344823399714, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.1328678614258402, 0.1450405510726396))},\n",
       " 'asian': {'Accuracy_diff': StatTestResult(statistic=0.030399999999999986, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.05913925517414949, 0.11993925517414945)),\n",
       "  'Precision_diff': StatTestResult(statistic=0.018488777078749054, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.08312843130270478, 0.1201059854602029))},\n",
       " 'black': {'Accuracy_diff': StatTestResult(statistic=-0.018800000000000004, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.10177294040887777, 0.06417294040887778)),\n",
       "  'Precision_diff': StatTestResult(statistic=-0.12259888613669702, p_value=1.0, is_significant=False, test_name='bootstrap_mean', critical_value=None, effect_size=None, confidence_interval=(-0.38432262467313105, 0.13912485239973704))}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_test_results"
   ]
>>>>>>> 6d5d91d719cd19268f8a746cc04da2e4ea9866ac
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equiboots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
