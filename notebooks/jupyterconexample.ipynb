{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bias and Fairness Assessment (Binary Classification: Adult Income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Assessing Machine Learning models for bias and fairness is of great importance:\n",
    "\n",
    "- Prevent Discrimination\n",
    "  - Avoid unfair treatment based on protected attributes.\n",
    "\n",
    "- Meet Legal Standards\n",
    "  - Ensure compliance with laws and anti-discrimination acts.\n",
    "\n",
    "- Build Trust\n",
    "  - Fair models are more accepted by users, stakeholders, and regulators.\n",
    "\n",
    "- Expose Hidden Gaps\n",
    "  - Surface performance differences across demographic subgroups.\n",
    "\n",
    "- Promote Ethical AI\n",
    "  - Prevent reinforcement of societal or historical biases in data.\n",
    "\n",
    "- Enable Accountability\n",
    "  - Make models more transparent and open to external review.\n",
    "\n",
    "- Guide Fairness Fixes\n",
    "  - Identify where to apply debiasing or fairness-enhancing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Dataset Overview: UCI Adult Income Dataset\n",
    "The **Adult Income dataset** (also known as the **Census Income** dataset) originates from the **UCI Machine Learning Repository**. It was extracted from the 1994 U.S. Census database and is widely used for benchmarking classification models, especially in fairness and bias research.\n",
    "\n",
    "The task is to **predict whether an individual earns more than $50K per year** based on features such as age, education, occupation, and marital status.\n",
    "\n",
    "- Target variable: income (binary: <=50K or >50K)\n",
    "\n",
    "- Samples: 48,842\n",
    "\n",
    "- Features: 14 demographic and employment-related attributes\n",
    "\n",
    "- Use case: Benchmarking algorithms, fairness audits, and bias mitigation\n",
    "\n",
    "Due to its inclusion of sensitive attributes (e.g., sex, race), it’s commonly used in studies evaluating algorithmic fairness and disparate impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "In this notebook, we’ll train an XGBoost model to predict whether an individual’s annual income exceeds \\$50K and then evaluate its performance and fairness across different demographic groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Step 1: Install and import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install equiboots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "adult = adult.data.features.join(adult.data.targets, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Basic Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 1. Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "adult.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 2. Copy DataFrame for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adult.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 3. Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_merge(val):\n",
    "    if val == \"<=50K\" or val == \"<=50K.\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"] = df[\"income\"].apply(outcome_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sex, count and percentages above_50k\n",
    "\n",
    "income_by_sex = df.groupby(\"sex\")[\"income\"].agg(\n",
    "    [\"count\", lambda x: (x.sum() / x.count()) * 100]\n",
    ")\n",
    "income_by_sex.columns = [\"count\", \"percentage_above_50k\"]\n",
    "income_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  race, count and percentages above_50k\n",
    "\n",
    "income_by_race = df.groupby(\"race\")[\"income\"].agg(\n",
    "    [\"count\", lambda x: (x.sum() / x.count()) * 100]\n",
    ")\n",
    "income_by_race.columns = [\"count\", \"percentage_above_50k\"]\n",
    "income_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 4. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    if isinstance(X[col], object):\n",
    "        X[col] = X[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(eval_metric=\"logloss\", random_state=42, enable_categorical=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Evaluate XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Bias and Fairness Analysis with EquiBoots\n",
    "\n",
    "**Equiboots supports a point estimate fairness analysis on a model's operating point (e.g., optimal threshold) as well as on multiple bootstraps with replacement.**\n",
    "\n",
    "\n",
    "To initialize an analysis with equiboots:\n",
    "\n",
    "1. Define a fairness Dataframe with the variables of interest.\n",
    "2. Initialize an equiboots object using:\n",
    "    - Ground truth (y_true)\n",
    "    - Model probabilities (y_prob)\n",
    "    - Model predictions (y_pred)\n",
    "3. Identify the columns/variables that we will be assessing (e.g., race, sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equiboots as eqb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions and true values\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "X_test[['race', 'sex']] = X_test[['race', 'sex']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Point Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = ['race', 'sex']\n",
    "\n",
    "fairness_df = X_test[sensitive_features].reset_index(drop=True)\n",
    "\n",
    "eq = eqb.EquiBoots(y_true=y_test, y_pred=y_pred, y_prob=y_prob, fairness_df=fairness_df, fairness_vars=sensitive_features)\n",
    "\n",
    "eq.grouper(groupings_vars=sensitive_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_race_data = eq.slicer(\"race\")\n",
    "sliced_sex_data = eq.slicer(\"sex\")\n",
    "\n",
    "race_metrics = eq.get_metrics(sliced_race_data)\n",
    "sex_metrics = eq.get_metrics(sliced_sex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqb.eq_plot_group_curves(\n",
    "    sliced_race_data,\n",
    "    curve_type=\"roc\",\n",
    "    title=\"ROC AUC by Race Group\",\n",
    "    exclude_groups=['Other', 'Amer-Indian-Eskimo']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"test_type\": \"chi_square\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results_race = eq.analyze_statistical_significance(race_metrics, \"race\", test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results_sex = eq.analyze_statistical_significance(sex_metrics, \"sex\", test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_metrics.pop('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqb.eq_plot_metrics_forest(\n",
    "    group_metrics=race_metrics,\n",
    "    metric_name=\"dkdk\",\n",
    "    title=\"Forest Plot: Accuracy Across Groups\",\n",
    "    reference_group=\"White\",\n",
    "    statistical_tests=stat_test_results_race,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equiboots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
