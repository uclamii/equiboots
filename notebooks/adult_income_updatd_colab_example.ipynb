{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWNzbca5Mf0x"
   },
   "source": [
    "# Bias and Fairness Assessment (Binary Classification: Adult Income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQKjeKFGV4ut"
   },
   "source": [
    "Assessing Machine Learning models for bias and fairness is of great importance:\n",
    "\n",
    "- Prevent Discrimination\n",
    "  - Avoid unfair treatment based on protected attributes.\n",
    "\n",
    "- Meet Legal Standards\n",
    "  - Ensure compliance with laws and anti-discrimination acts.\n",
    "\n",
    "- Build Trust\n",
    "  - Fair models are more accepted by users, stakeholders, and regulators.\n",
    "\n",
    "- Expose Hidden Gaps\n",
    "  - Surface performance differences across demographic subgroups.\n",
    "\n",
    "- Promote Ethical AI\n",
    "  - Prevent reinforcement of societal or historical biases in data.\n",
    "\n",
    "- Enable Accountability\n",
    "  - Make models more transparent and open to external review.\n",
    "\n",
    "- Guide Fairness Fixes\n",
    "  - Identify where to apply debiasing or fairness-enhancing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2AbxsXsMkPj"
   },
   "source": [
    "## Dataset Overview: UCI Adult Income Dataset\n",
    "The **Adult Income dataset** (also known as the **Census Income** dataset) originates from the **UCI Machine Learning Repository**. It was extracted from the 1994 U.S. Census database and is widely used for benchmarking classification models, especially in fairness and bias research.\n",
    "\n",
    "The task is to **predict whether an individual earns more than $50K per year** based on features such as age, education, occupation, and marital status.\n",
    "\n",
    "- Target variable: income (binary: <=50K or >50K)\n",
    "\n",
    "- Samples: 48,842\n",
    "\n",
    "- Features: 14 demographic and employment-related attributes\n",
    "\n",
    "- Use case: Benchmarking algorithms, fairness audits, and bias mitigation\n",
    "\n",
    "Due to its inclusion of sensitive attributes (e.g., sex, race), it’s commonly used in studies evaluating algorithmic fairness and disparate impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wfzEPOyMqeP"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulxJaIRQMlwn"
   },
   "source": [
    "In this notebook, we’ll train an XGBoost model to predict whether an individual’s annual income exceeds \\$50K and then evaluate its performance and fairness across different demographic groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IGcBI4ZMoXk"
   },
   "source": [
    "### Step 1: Install and import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSbTAei9TZJH",
    "outputId": "218f0652-fb51-45a6-bb46-4d31b07a764d"
   },
   "outputs": [],
   "source": [
    "! pip install equiboots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAxWExLnMuRg",
    "outputId": "1660e1f3-cbdd-4c9e-8685-e3960e2bea36"
   },
   "outputs": [],
   "source": [
    "! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MirLIXB9MxFN"
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfFb02NyMyBn"
   },
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "adult = adult.data.features.join(adult.data.targets, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "GoCXwqsQTCQQ",
    "outputId": "d9ba1706-608f-42d1-c615-d3f2d19334c7"
   },
   "outputs": [],
   "source": [
    "adult.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMQ5N47vMzXZ"
   },
   "source": [
    "## Basic Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYBb5DsxMz8T"
   },
   "source": [
    "### 1. Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF_DtdPTM1Yy"
   },
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "adult.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-p7NlTeJNstX"
   },
   "source": [
    "### 2. Copy DataFrame for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akVIVbXmNqTw"
   },
   "outputs": [],
   "source": [
    "df = adult.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "eXRmeg_8wiA2",
    "outputId": "42b4d3f2-f56e-439b-ff2b-7d8386055f0a"
   },
   "outputs": [],
   "source": [
    "adult[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fbu-MFeMM2sz"
   },
   "source": [
    "### 3. Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K036CclmWbPl"
   },
   "outputs": [],
   "source": [
    "def outcome_merge(val):\n",
    "    if val == \"<=50K\" or val == \"<=50K.\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N74NyjgtWRMr"
   },
   "outputs": [],
   "source": [
    "df[\"income\"] = df[\"income\"].apply(outcome_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "PE-G6TJTbLpB",
    "outputId": "e636728c-4686-4517-e8d1-839728d4521b"
   },
   "outputs": [],
   "source": [
    "#  sex, count and percentages above_50k\n",
    "\n",
    "income_by_sex = df.groupby(\"sex\")[\"income\"].agg(\n",
    "    [\"count\", lambda x: (x.sum() / x.count()) * 100]\n",
    ")\n",
    "income_by_sex.columns = [\"count\", \"percentage_above_50k\"]\n",
    "income_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "bHf0GSvkaZge",
    "outputId": "472b4643-d980-4e62-b755-194dea8fc720"
   },
   "outputs": [],
   "source": [
    "#  race, count and percentages above_50k\n",
    "\n",
    "income_by_race = df.groupby(\"race\")[\"income\"].agg(\n",
    "    [\"count\", lambda x: (x.sum() / x.count()) * 100]\n",
    ")\n",
    "income_by_race.columns = [\"count\", \"percentage_above_50k\"]\n",
    "income_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBAi0x6IM5Yv"
   },
   "source": [
    "### 4. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lfe5t6IZM60e"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVEzdrADAzP9"
   },
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    if isinstance(X[col], object):\n",
    "        X[col] = X[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmUyh5dzM8dU"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "QTlGNyrHwIPW",
    "outputId": "55556e74-be28-4901-aba2-e229a703e3e3"
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uRLCghYM9Ub"
   },
   "source": [
    "## Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "ifiKclAeM-1H",
    "outputId": "e80c069d-3023-4cab-ace4-b9efab5fdd25"
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(eval_metric=\"logloss\", random_state=42, enable_categorical=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqe2kl-7NAhB"
   },
   "source": [
    "## Evaluate XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvULzSB5NCMn",
    "outputId": "4c629d91-29f3-4860-8fb4-7c46f28066dc"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKydvDxLThP9"
   },
   "source": [
    "# Bias and Fairness Analysis with EquiBoots\n",
    "\n",
    "**Equiboots supports a point estimate fairness analysis on a model's operating point (e.g., optimal threshold) as well as on multiple bootstraps with replacement.**\n",
    "\n",
    "\n",
    "To initialize an analysis with equiboots:\n",
    "\n",
    "1. Define a fairness Dataframe with the variables of interest.\n",
    "2. Initialize an equiboots object using:\n",
    "    - Ground truth (y_true)\n",
    "    - Model probabilities (y_prob)\n",
    "    - Model predictions (y_pred)\n",
    "3. Identify the columns/variables that we will be assessing (e.g., race, sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "id0rzf9HTgd1"
   },
   "outputs": [],
   "source": [
    "import equiboots as eqb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RplCUsl2TzNB"
   },
   "source": [
    "## Point Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZDhrQZvTesJ",
    "outputId": "6de3d578-2ef4-4a76-c6e8-2a3a12f32a4e"
   },
   "outputs": [],
   "source": [
    "# get predictions and true values\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "X_test[[\"race\", \"sex\"]] = X_test[[\"race\", \"sex\"]].astype(str)\n",
    "\n",
    "\n",
    "# Create fairness DataFrame\n",
    "fairness_df = X_test[[\"race\", \"sex\"]].reset_index()\n",
    "\n",
    "eq = eqb.EquiBoots(\n",
    "    y_true=y_test,\n",
    "    y_prob=y_prob,\n",
    "    y_pred=y_pred,\n",
    "    fairness_df=fairness_df,\n",
    "    fairness_vars=[\"race\", \"sex\"],\n",
    ")\n",
    "\n",
    "# grouping by variables' groups (e.g., Male, Female, etc)\n",
    "eq.grouper(groupings_vars=[\"race\", \"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4ObfcV_U58T"
   },
   "outputs": [],
   "source": [
    "# slicing data by variable of interest\n",
    "sliced_race_data = eq.slicer(\"race\")\n",
    "\n",
    "# generating performance metrics (dependent on prediction task, equiboots default task=\"binary_classification\")\n",
    "race_metrics = eq.get_metrics(sliced_race_data)\n",
    "\n",
    "# slicing and generating metrics for sex\n",
    "sliced_sex_data = eq.slicer(\"sex\")\n",
    "sex_metrics = eq.get_metrics(sliced_sex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_VE1Z7cVOGw"
   },
   "outputs": [],
   "source": [
    "## generating statistical significnace in tests\n",
    "test_config = {\n",
    "    \"test_type\": \"chi_square\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "}\n",
    "\n",
    "# stat test race\n",
    "stat_test_results_race = eq.analyze_statistical_significance(\n",
    "    race_metrics, \"race\", test_config\n",
    ")\n",
    "\n",
    "# stat test sex\n",
    "stat_test_results_sex = eq.analyze_statistical_significance(\n",
    "    sex_metrics, \"sex\", test_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nU_CsBvoXg6R",
    "outputId": "78dc7707-9975-4979-ef3a-3183ae764481"
   },
   "outputs": [],
   "source": [
    "stat_test_results_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF2wOGKOUNFO"
   },
   "source": [
    "## Signficance plots\n",
    "\n",
    "- Equiboots supports statistical testing to assess significance in metrics differences.\n",
    "\n",
    "- Specifically the omnibus and pairwise chi-square test is used to assess significance between groups.\n",
    "\n",
    "- Reference groups to compare against can be provided at the initialization of the Equiboots object:\n",
    "  - using  (reference_groups=[\"white\",\"female\"]),\n",
    "  - otherwise the groups with highest number of observations is automatically selected\n",
    "\n",
    "- Below we plot the different race and sex groups and look at how their performance differs for each of these groups.\n",
    "\n",
    "- We conduct statistical signficance tests to determine firstly whether there is a difference between:\n",
    "  - the groups (omnibus test) this is represented by the asterix (*),\n",
    "  - and if significant, then we determine which groups are statistically signficance these are shown with the (▲).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uAD53rvbH-S"
   },
   "outputs": [],
   "source": [
    "overall_stat_results = {\n",
    "    \"sex\": stat_test_results_sex,\n",
    "    \"race\": stat_test_results_race,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 965
    },
    "id": "RwGRiu6sX0OF",
    "outputId": "5bddd4c0-ab13-4c9b-d92f-1291c7d7d865"
   },
   "outputs": [],
   "source": [
    "eqb.eq_group_metrics_point_plot(\n",
    "    group_metrics=[race_metrics, sex_metrics],\n",
    "    metric_cols=[\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "    ],\n",
    "    category_names=[\"race\", \"sex\"],\n",
    "    figsize=(6, 8),\n",
    "    include_legend=True,\n",
    "    plot_thresholds=(0.9, 1.1),\n",
    "    raw_metrics=True,\n",
    "    show_grid=True,\n",
    "    y_lim=(0, 1),\n",
    "    statistical_tests=overall_stat_results,\n",
    "    y_lims={(0, 0): (0.70, 1.0), (0, 1): (0.70, 1.0)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY8ELENUYAr6"
   },
   "outputs": [],
   "source": [
    "from equiboots.tables import metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47IeJfgYX5fN"
   },
   "outputs": [],
   "source": [
    "stat_metrics_table_point = metrics_table(\n",
    "    race_metrics, statistical_tests=stat_test_results_race, reference_group=\"White\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "QvB6iZvPYBKW",
    "outputId": "c8f99687-2e63-45fc-8766-a1edd99e1c88"
   },
   "outputs": [],
   "source": [
    "# table with metrics per group and statistical significance shown on columns for\n",
    "# omnibus and/or pairwise\n",
    "stat_metrics_table_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forest plots** within this context provide a clear way to visualize point estimates across multiple groups, making it easy to compare performance metrics side by side. Below is but one example. Available metrics are as follows:\n",
    "\n",
    "\n",
    "`'Accuracy'`, `'Precision'`, `'Recall'`, `'F1 Score'`, `'Specificity'`,  \n",
    "`'TP Rate'`, `'FP Rate'`, `'FN Rate'`, `'TN Rate'`, `'TP'`, `'FP'`,  \n",
    "`'FN'`, `'TN'`, `'Prevalence'`, `'Predicted Prevalence'`, `'ROC AUC'`,  \n",
    "`'Average Precision Score'`, `'Log Loss'`, `'Brier Score'`, `'Calibration AUC'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqb.eq_plot_metrics_forest(\n",
    "    group_metrics=race_metrics,\n",
    "    metric_name=\"Prevalence\",\n",
    "    title=\"Forest Plot: Race Group Point Estimates\",\n",
    "    reference_group=\"White\",\n",
    "    figsize=(8, 6),\n",
    "    sort_groups=True,\n",
    "    ascending=False,\n",
    "    statistical_tests=stat_test_results_race,\n",
    "    save_path=\"./images\",\n",
    "    filename=\"prevalance_forest_point_est_race\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bvd2CxDwC57"
   },
   "source": [
    "## Effect Size\n",
    "\n",
    "EquiBoots also calculates effect size when we are dealing with point estimates. In this case we can see the effect size for all of the results is low (under 0.2) with the highest being 0.11. This indicates that although statistical signficance was found it is not necessary a strong finding.\n",
    "\n",
    "According to [source](www.ibm.com/docs/en/cognos-analytics/12.0.x), for Cramer's V:\n",
    "\n",
    "- ES ≤ 0.2 is interpreted as a weak result.\n",
    "- 0.2 < ES ≤ 0.6 is interpreted as a moderate result.\n",
    "- ES > 0.6 is interpreted as a strong result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "fLPM5F7RRiX5",
    "outputId": "757ec6da-80d7-4174-caba-0b5c988a48aa"
   },
   "outputs": [],
   "source": [
    "eqb.plot_effect_sizes(\n",
    "    stat_test_results_race,\n",
    "    xlabel=\"Race & Ethnicity\",\n",
    "    ylabel=\"Effect size\",\n",
    "    title=\"Race/Ethnicity Effect Sizes\",\n",
    "    figsize=(10, 4),\n",
    "    # rotation=0,\n",
    "    save_path=\"/home/lshpaner/Python_Projects/equiboots/notebooks/images\",\n",
    "    filename=\"race_effect_size\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJg9jiQxUUF0"
   },
   "source": [
    "## Concluding remarks for the Point Estimate analysis on the model's Operating point\n",
    "\n",
    "- There are statistically significant differences in Accuracy, Precision, and\n",
    "Recall across both race and sex categories (based on the omnibus test).\n",
    "- Pairwise analysis shows that these differences are statistically significant for all racial groups when compared to the reference group (White), except for Asian-Pac-Islander.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogkkZj_FUWI4"
   },
   "source": [
    "## Precision-Recall, ROC, and Calibration Curves by Race\n",
    "These plots look at how performance is different across the different race groups.\n",
    "We choose to exclude certain groups from the analysis because there are not enough members of these groups to make a\n",
    "fair comparison between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "zI5wloDkZwf1",
    "outputId": "6ac2f0e8-b1ab-4f3b-9fd2-8937ff59d4e1"
   },
   "outputs": [],
   "source": [
    "# PR curves\n",
    "eqb.eq_plot_group_curves(\n",
    "    sliced_race_data,\n",
    "    curve_type=\"pr\",\n",
    "    subplots=False,\n",
    "    figsize=(7, 7),\n",
    "    title=\"Precision-Recall by Race Group\",\n",
    "    exclude_groups=[\"Amer-Indian-Eskimo\", \"Other\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "N5s2lfp9aGFu",
    "outputId": "777e02a1-6927-477a-9b1e-80c3743b1ea6"
   },
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "eqb.eq_plot_group_curves(\n",
    "    sliced_race_data,\n",
    "    curve_type=\"roc\",\n",
    "    title=\"ROC AUC by Race Group\",\n",
    "    figsize=(7, 7),\n",
    "    decimal_places=2,\n",
    "    subplots=False,\n",
    "    exclude_groups=[\"Amer-Indian-Eskimo\", \"Other\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "D4XfMzRwZdTc",
    "outputId": "114cab06-61cd-4d76-b670-426f5a5a6d29"
   },
   "outputs": [],
   "source": [
    "# calibration curves\n",
    "eqb.eq_plot_group_curves(\n",
    "    sliced_race_data,\n",
    "    curve_type=\"calibration\",\n",
    "    shade_area=True,\n",
    "    title=\"Calibration by Race Group\",\n",
    "    exclude_groups=[\"Amer-Indian-Eskimo\", \"Other\"],\n",
    "    subplots=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "NO-edMrtVkla",
    "outputId": "1f803419-9832-4cf6-d35f-f7ee52ee491b"
   },
   "outputs": [],
   "source": [
    "# calibration curves per group\n",
    "eqb.eq_plot_group_curves(\n",
    "    sliced_race_data,\n",
    "    curve_type=\"calibration\",\n",
    "    shade_area=True,\n",
    "    title=\"Calibration by Race Group\",\n",
    "    exclude_groups=[\"Amer-Indian-Eskimo\", \"Other\"],\n",
    "    subplots=True,\n",
    "    n_cols=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j7RqvmNUaF8"
   },
   "source": [
    "### Concluding remarks for the Point Estimate analysis on the model's ROC, PR, and Calibration Curves\n",
    "\n",
    "- PRAUC for all race groups shows no visual differences.\n",
    "- For AUC ROC, the AUC for the Black population is higher.\n",
    "- In terms of calibration curves, the least calibrated group is Asian-Pac-Islander.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyYS4cOsZfy5"
   },
   "source": [
    "## Bootstrap Estimates\n",
    "\n",
    "Bootstrap estimates:\n",
    "- randomly sampling fairness_df, y_true, y_prob, and y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29WusiHqZhcW",
    "outputId": "1cd0efe5-1813-484d-dac7-9e94d4f1a829"
   },
   "outputs": [],
   "source": [
    "# setting fixed seed for reproducibility\n",
    "# Alternatively, seeds can be set after initialization\n",
    "int_list = np.linspace(0, len(y_test), num=len(y_test), dtype=int).tolist()\n",
    "\n",
    "eq2 = eqb.EquiBoots(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_prob=y_prob,\n",
    "    fairness_df=fairness_df,\n",
    "    fairness_vars=[\"race\"],\n",
    "    seeds=int_list,\n",
    "    reference_groups=[\"White\"],\n",
    "    task=\"binary_classification\",\n",
    "    bootstrap_flag=True,\n",
    "    num_bootstraps=5001,\n",
    "    boot_sample_size=len(y_test),  # whole length of test set\n",
    "    group_min_size=150,  # any group with samples below this number will be ignored\n",
    "    balanced=False,  # False is stratified (i.e., maintaining groups proportions), True is balanced (equal proportions)\n",
    "    stratify_by_outcome=False,  # True maintain initial dataset outcome proportions per group\n",
    ")\n",
    "\n",
    "# Set seeds after initialization\n",
    "eq2.set_fix_seeds(int_list)\n",
    "print(\"seeds\", eq2.seeds)\n",
    "\n",
    "# group bootstraps by grouping variables (e.g., race)\n",
    "eq2.grouper(groupings_vars=[\"race\"])\n",
    "\n",
    "# slice by variable and assign to a variable\n",
    "# race related bootstraps\n",
    "boots_race_data = eq2.slicer(\"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izTeWlr-aoi7"
   },
   "source": [
    "### Calculate disparities\n",
    "\n",
    "- In the context of bias and fairness in machine learning, disparity refers to the differences in model performance, predictions, or outcomes across different demographic or sensitive groups.\n",
    "- It quantifies how a model's behavior varies for subgroups based on attributes like race, sex, age, or other characteristics.\n",
    "\n",
    "Here's how you can represent the disparity ratio for a given metric (M) and a specific group (G) compared to a reference group (R):\n",
    "\n",
    "$$\\text{Disparity Ratio} = \\frac{M(G)}{M(R)}$$\n",
    "\n",
    "And here's how you can represent the disparity difference:\n",
    "\n",
    "$$\\text{Disparity Difference} = M(G) - M(R)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $M(G)$ is the value of the metric for group G.\n",
    "- $M(R)$ is the value of the metric for the reference group R.\n",
    "\n",
    "\n",
    "For example, if you are looking at the \"Predicted Prevalence\" metric (the proportion of individuals predicted to have a positive outcome), the Predicted Prevalence Disparity Ratio for a group (e.g., \"Black\") compared to a reference group (e.g., \"White\") would be:\n",
    "\n",
    "- $$ \\text{Predicted Prevalence Disparity Ratio} = \\frac{\\text{Predicted Prevalence (Black)}}{\\text{Predicted Prevalence (White)}} $$\n",
    "\n",
    "- $$ \\text{Predicted Prevalence Disparity difference} = \\text{Predicted Prevalence (Black)}-\\text{Predicted Prevalence (White)} $$\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "- Disparity analysis is crucial for identifying potential unfairness in a model's predictions and understanding how it impacts different populations.\n",
    "- Tools like EquiBoots help to quantify and visualize these disparities, allowing for a more informed assessment of model fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fBCkNsid7NK",
    "outputId": "9d01a5d2-23bb-487b-8bc6-c67ab3dc165c"
   },
   "outputs": [],
   "source": [
    "# compute binary classification metrics wrt to race\n",
    "boots_race_metrics = eq2.get_metrics(boots_race_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX31CGEaamjd"
   },
   "outputs": [],
   "source": [
    "dispa = eq2.calculate_disparities(boots_race_metrics, \"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfrHSYnTXTOR"
   },
   "source": [
    "## Calculating Disparity\n",
    "Here we look at the disparity between the reference group which in this case is White, with the other race groups.\n",
    "If we compare the prevalence with the predicted prevalence we are able to see **if** there is a difference. In this case we do not see a noticable difference between predicted prevalence and actual prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "B_uefThEa2Fw",
    "outputId": "99ac7fa0-dc13-4187-87f2-3bf98abf2a68"
   },
   "outputs": [],
   "source": [
    "eqb.eq_group_metrics_plot(\n",
    "    group_metrics=dispa,\n",
    "    metric_cols=[\n",
    "        \"Accuracy_Ratio\",\n",
    "        \"Precision_Ratio\",\n",
    "        \"Predicted_Prevalence_Ratio\",\n",
    "        \"Prevalence_Ratio\",\n",
    "        \"FP_Rate_Ratio\",\n",
    "        \"TN_Rate_Ratio\",\n",
    "        \"Recall_Ratio\",\n",
    "    ],\n",
    "    name=\"race\",\n",
    "    categories=\"all\",\n",
    "    plot_type=\"violinplot\",\n",
    "    color_by_group=True,\n",
    "    show_grid=False,\n",
    "    strict_layout=True,\n",
    "    leg_cols=7,\n",
    "    # plot_thresholds=[0.9, 1.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaLNRBsEUetZ"
   },
   "source": [
    "### Concluding Remarks for the Bootstrap Disparity Ratios\n",
    "\n",
    "- Prevalence:\n",
    "  - Among all bootstraps, the Black population is around 50% less likely to have a higher income.\n",
    "  - The Asian-Pac-Islander group is a multimodal distribution of ratios, with the biggest mode close to a ratio of 1 and two other modes: one around 1.3 times higher than the reference White group and another one around 1.7 times higher.\n",
    "- Predicted prevalence:\n",
    "  - depicts the same behavior, suggesting that the model is following some inherent disparities in the domain of income.\n",
    "- The False positive rate ratio in the Black population is around 50% less times with respect to the reference group.\n",
    "- In the remaining charts the disparities are overlapping the reference (1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGDq8HT4arRT"
   },
   "source": [
    "### Calculate Disparity differences in metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YugU5MhanHi"
   },
   "outputs": [],
   "source": [
    "diffs = eq2.calculate_differences(boots_race_metrics, \"race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "9X7K9s3jgtvB",
    "outputId": "d919ee05-ec75-43c0-fbbd-773adfa451c6"
   },
   "outputs": [],
   "source": [
    "eqb.eq_group_metrics_plot(\n",
    "    group_metrics=diffs,\n",
    "    metric_cols=[\n",
    "        \"Accuracy_diff\",\n",
    "        \"Precision_diff\",\n",
    "        \"Predicted_Prevalence_diff\",\n",
    "        \"Prevalence_diff\",\n",
    "        \"FP_Rate_diff\",\n",
    "        \"TN_Rate_diff\",\n",
    "        \"Recall_diff\",\n",
    "    ],\n",
    "    name=\"race\",\n",
    "    categories=\"all\",\n",
    "    plot_type=\"violinplot\",\n",
    "    color_by_group=True,\n",
    "    show_grid=False,\n",
    "    strict_layout=True,\n",
    "    leg_cols=7,\n",
    "    # plot_thresholds=[0.9, 1.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb0B-9jFa68l"
   },
   "source": [
    "### Calculate statistical signficance\n",
    "\n",
    "- We are using a bootstrap-based approach to determine if the observed differences in various model performance metrics (like Accuracy, Precision, Recall, etc.) between each demographic group and the chosen reference group (White) are statistically significant.\n",
    "\n",
    "- The bootstrap method involves repeatedly resampling the data to create multiple versions of the metrics for each group. By comparing the distribution of these bootstrapped metric differences to a null hypothesis of no difference, we can calculate a p-value.\n",
    "\n",
    "- This p-value, adjusted for multiple comparisons using a method like Bonferroni, helps us conclude whether the observed disparities are likely due to random chance or represent a true, statistically significant difference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lpo3uJbCauB3"
   },
   "outputs": [],
   "source": [
    "# metrics to perform a statistical test\n",
    "metrics_boot = [\n",
    "    \"Accuracy_diff\",\n",
    "    \"Precision_diff\",\n",
    "    \"Recall_diff\",\n",
    "    \"F1_Score_diff\",\n",
    "    \"Specificity_diff\",\n",
    "    \"TP_Rate_diff\",\n",
    "    \"FP_Rate_diff\",\n",
    "    \"FN_Rate_diff\",\n",
    "    \"TN_Rate_diff\",\n",
    "    \"Prevalence_diff\",\n",
    "    \"Predicted_Prevalence_diff\",\n",
    "    \"ROC_AUC_diff\",\n",
    "    \"Average_Precision_Score_diff\",\n",
    "    \"Log_Loss_diff\",\n",
    "    \"Brier_Score_diff\",\n",
    "    \"Calibration_AUC_diff\",\n",
    "]\n",
    "\n",
    "# configuration dictionary to provide parameters around statistical testing\n",
    "test_config = {\n",
    "    \"test_type\": \"bootstrap_test\",\n",
    "    \"alpha\": 0.05,\n",
    "    \"adjust_method\": \"bonferroni\",\n",
    "    \"confidence_level\": 0.95,\n",
    "    \"classification_task\": \"binary_classification\",\n",
    "    \"tail_type\": \"two_tailed\",\n",
    "    \"metrics\": metrics_boot,\n",
    "}\n",
    "\n",
    "\n",
    "stat_test_results = eq.analyze_statistical_significance(\n",
    "    metric_dict=boots_race_metrics,  # pass variable sliced metrics\n",
    "    var_name=\"race\",  # variable name\n",
    "    test_config=test_config,  # configuration\n",
    "    differences=diffs,  # the differences of each race group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHz26IutbFfW"
   },
   "source": [
    "### Table of statistical signficance (difference between metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Akp8J7u_bIyz"
   },
   "outputs": [],
   "source": [
    "stat_metrics_table_diff = metrics_table(\n",
    "    boots_race_metrics,\n",
    "    statistical_tests=stat_test_results,\n",
    "    differences=diffs,\n",
    "    reference_group=\"White\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "TmDQBzvFXawc",
    "outputId": "5f7ba66d-3d69-4423-9491-4896916c3407"
   },
   "outputs": [],
   "source": [
    "# differences of each race group wrt reference group\n",
    "# reference group differences are all zero not shown for simplicity\n",
    "# * depicts statistical significance\n",
    "stat_metrics_table_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ77dNMja_1J"
   },
   "source": [
    "### Plot statistical signficance between the differences of metrics\n",
    "\n",
    "This section plots the metrics for each group against each other.\n",
    "Statistical tests are used to determine whether these differences are statistically significant.\n",
    "Statistical signficance is shown with an asterix (*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H5j-tRgqa9qQ",
    "outputId": "1133d87d-c462-4e7a-de2f-0f5af239b29f"
   },
   "outputs": [],
   "source": [
    "eqb.eq_group_metrics_plot(\n",
    "    group_metrics=diffs,\n",
    "    metric_cols=metrics_boot,\n",
    "    name=\"race\",\n",
    "    categories=\"all\",\n",
    "    figsize=(20, 10),\n",
    "    plot_type=\"violinplot\",\n",
    "    color_by_group=True,\n",
    "    show_grid=True,\n",
    "    max_cols=6,\n",
    "    strict_layout=True,\n",
    "    save_path=\"./images\",\n",
    "    show_pass_fail=False,\n",
    "    statistical_tests=stat_test_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped Forest Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqb.eq_plot_bootstrap_forest(\n",
    "    group_boot_metrics=boots_race_metrics,\n",
    "    metric=\"ROC AUC\",\n",
    "    reference_group=\"White\",\n",
    "    title=\"AUROC - Bootstrapped Race Metrics\",\n",
    "    save_path=\"/home/lshpaner/Python_Projects/equiboots/notebooks/images\",\n",
    "    figsize=(8, 6),\n",
    "    filename=\"bootstrapped_roc_auc_race_metrics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqb.calculate_bootstrap_stats(group_boot_metrics=boots_race_metrics, metric=\"ROC AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2fZVL_7jwRE"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6V6o7sSnThlo"
   },
   "source": [
    "EquiBoots allow us to compare the performance of machine learning models across different race groups.\n",
    "\n",
    "We looked at both point estimates and bootstrapped estimates in this example and analysed their statistical signficance.\n",
    "\n",
    "Overall we found multiple metrics where performance was statistically different from the reference group in the point estimates examples. With the caveat that we also saw small effect sizes meaning not necessarily a strong difference.\n",
    "\n",
    "The bootstrapped examples also showed us where the model performance differed, when looking at the precision we can see a higher precision for Black sample (with statistical significance) however we cannot say that the model is biased as we also see a statistically signficant difference between the reference group (White sample) in terms of prevalence.\n",
    "\n",
    "- Differences in Accuracy, Precision, Specificity, FP rate, TN Rate, Prevalence, Predicted Prevalence, Log loss, and Brier Score are statistically significant for the Black population.\n",
    "- For the Asian-Pac-Islander population, the Calibration Curve AUC (with the 45-degree diagonal) is statistically significantly different from the reference.\n",
    "- This suggests that the model would improve from calibration.\n",
    "- Moreover, the prevalence disparity in outcome observed within the Black population is clearer in the Bootstrap analysis, evident in both prevalence and across most of the model's metrics"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "equi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
